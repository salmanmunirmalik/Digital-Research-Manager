/**
 * AI Research Agent API Routes
 * Simple chat interface with intelligent background processing
 * Handles task analysis, tool selection, and agent routing
 */

import { Router } from 'express';
import axios from 'axios';
import pool from "../../database/config.js";
import { getUserApiKey, getUserDefaultProvider } from './aiProviderKeys.js';
import { getApiForTask } from './apiTaskAssignments.js';
import { AIProviderFactory } from '../services/AIProviderFactory.js';
import { ChatMessage } from '../services/AIProvider.js';
import { UserContextRetriever } from '../services/UserContextRetriever.js';
import { EnhancedRAGSystem } from '../services/EnhancedRAGSystem.js';
import { ContinuousLearningEngine } from '../services/ContinuousLearningEngine.js';
import { SmartToolSelector, TaskRequirements } from '../services/SmartToolSelector.js';
import { TaskAnalysisEngine, TaskAnalysis } from '../services/TaskAnalysisEngine.js';
import { AgentFactory } from '../services/AgentFactory.js';

const router: Router = Router();

// ==============================================
// GET ENDPOINT - Health/Status check
// ==============================================

router.get('/', async (req: any, res) => {
  try {
    // Safety check for req.user
    if (!req.user) {
      return res.status(401).json({ error: 'Authentication required' });
    }

    res.json({
      status: 'active',
      message: 'AI Research Agent is ready',
      capabilities: [
        'chat',
        'task_analysis',
        'context_retrieval',
        'tool_selection',
        'agent_routing'
      ]
    });
  } catch (error: any) {
    console.error('Error in AI Research Agent GET:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
});

// ==============================================
// CHAT ENDPOINT - Main entry point
// ==============================================

router.post('/chat', async (req: any, res) => {
  try {
    const { message, conversation_history = [] } = req.body;
    const userId = req.user?.id;

    if (!message || !message.trim()) {
      return res.status(400).json({ error: 'Message is required' });
    }

    console.log(`ü§ñ AI Research Agent - User ${userId}: ${message.substring(0, 50)}...`);

    // TODO: Phase 2 - Implement background intelligence
    // 1. TaskAnalysisEngine - Analyze query intent
    // 2. UserContextRetriever - Get user's research context
    // 3. SmartToolSelector - Select best AI provider/model
    // 4. AgentRouter - Route to appropriate agent
    // 5. WorkflowOrchestrator - Handle complex workflows

    // For now, return a simple response
    // This will be replaced with intelligent processing
    const { response: responseText, apiUsed } = await processMessage(message, userId, conversation_history);

    res.json({
      content: responseText,
      apiUsed: apiUsed || null,
      timestamp: new Date().toISOString()
    });
  } catch (error: any) {
    console.error('Error in AI Research Agent chat:', error);
    res.status(500).json({ 
      error: 'Failed to process message', 
      details: error.message 
    });
  }
});

// ==============================================
// BACKGROUND INTELLIGENCE FUNCTIONS
// ==============================================

/**
 * Process user message with background intelligence
 * This is where all the magic happens behind the scenes
 */
async function processMessage(
  message: string, 
  userId: string, 
  conversationHistory: any[]
): Promise<{ response: string; apiUsed: string | null }> {
  // Step 1: Enhanced task analysis using TaskAnalysisEngine
  const taskAnalysis = TaskAnalysisEngine.analyzeTask(message);
  console.log(`üìä Task Analysis: ${taskAnalysis.taskType} (confidence: ${taskAnalysis.confidence})`);
  
  // Step 2: Get user's API assignment for this task (user preference)
  let apiAssignment = await getApiForTask(userId, taskAnalysis.taskType);
  
  // Step 3: If no user assignment, use Smart Tool Selector to recommend best provider
  if (!apiAssignment) {
    console.log(`üîç No user assignment found, using Smart Tool Selector...`);
    
    const availableProviders = await SmartToolSelector.getAvailableProviders(userId);
    
    if (availableProviders.length > 0) {
      const requirements: TaskRequirements = {
        taskType: taskAnalysis.taskType,
        complexity: taskAnalysis.estimatedComplexity,
        requiresContext: taskAnalysis.requiresContext,
        contextLength: taskAnalysis.contextRequirements?.minContextLength,
        qualityRequirement: taskAnalysis.qualityRequirement,
        speedRequirement: taskAnalysis.speedRequirement,
        costSensitivity: taskAnalysis.costSensitivity,
        requiresEmbeddings: taskAnalysis.contextRequirements?.requiresEmbeddings,
        requiresImageGeneration: taskAnalysis.taskType === 'image_creation'
      };
      
      const recommendation = await SmartToolSelector.selectBestProvider(
        requirements,
        availableProviders,
        userId
      );
      
      if (recommendation) {
        // Get API key for recommended provider
        const recommendedKey = await getUserApiKey(userId, recommendation.provider);
        if (recommendedKey) {
          // Get API key ID from database
          const keyResult = await pool.query(
            `SELECT id FROM ai_provider_keys WHERE user_id = $1 AND provider = $2 AND is_active = true LIMIT 1`,
            [userId, recommendation.provider]
          );
          
          apiAssignment = {
            apiKeyId: keyResult.rows[0]?.id || '',
            provider: recommendation.provider,
            providerName: recommendation.providerName,
            apiKey: recommendedKey
          };
          console.log(`‚ú® Smart selection: ${recommendation.providerName} (score: ${recommendation.score.toFixed(1)})`);
          console.log(`   Reasons: ${recommendation.reasons.join(', ')}`);
        }
      }
    }
  }
  
  if (!apiAssignment) {
    // No API available - return helpful message
    return {
      response: `I understand you want me to help with "${taskAnalysis.taskType}", but you haven't configured any API keys yet.\n\n` +
               `Please go to Settings ‚Üí API Management and add your API keys (e.g., OpenAI, Google Gemini, Anthropic Claude) to get started.\n\n` +
               `Once configured, I'll automatically select the best API for each task!`,
      apiUsed: null
    };
  }
  
  console.log(`üîß Using API: ${apiAssignment.providerName} (${apiAssignment.provider})`);
  
  // Step 4: Check if we should use a specialized agent
  const useAgent = AgentFactory.isAgentSupported(taskAnalysis.taskType);
  
  if (useAgent) {
    console.log(`ü§ñ Using specialized agent: ${taskAnalysis.taskType}`);
    try {
      const agent = AgentFactory.createAgent(taskAnalysis.taskType);
      
      // Retrieve enhanced user context with weighted scoring if needed
      const userContext = taskAnalysis.requiresContext 
        ? await EnhancedRAGSystem.retrieveEnhancedContext(userId, message)
        : { user: null, weightedResults: [], totalRelevance: 0, sourcesUsed: [] };
      
      // Prepare agent input based on task type
      // Convert EnhancedRAGSystem format to agent-compatible format
      const agentCompatibleContext = convertEnhancedContextToAgentFormat(userContext);
      const agentInput = {
        query: message,
        ...taskAnalysis.parameters,
        context: agentCompatibleContext
      };
      
      // Execute agent
      const agentResult = await agent.execute(agentInput, {
        userContext: agentCompatibleContext,
        conversationHistory,
        additionalData: { userId }
      }, {
        provider: apiAssignment.provider,
        apiKey: apiAssignment.apiKey
      });
      
      if (agentResult.success) {
        // Format agent result for chat response
        let formattedResponse: string;
        if (typeof agentResult.content === 'string') {
          formattedResponse = agentResult.content;
        } else if (agentResult.content) {
          formattedResponse = JSON.stringify(agentResult.content, null, 2);
        } else {
          formattedResponse = 'Agent execution completed successfully.';
        }
        
        return {
          response: formattedResponse,
          apiUsed: apiAssignment.providerName
        };
      } else {
        // Agent failed, fall back to direct API call
        console.log(`‚ö†Ô∏è Agent execution failed, falling back to direct API call`);
      }
    } catch (error: any) {
      console.error(`Error executing agent: ${error.message}`);
      // Fall through to direct API call
    }
  }
  
  // Step 5: Retrieve enhanced user context with weighted scoring - only if needed
  const userContext = taskAnalysis.requiresContext 
    ? await EnhancedRAGSystem.retrieveEnhancedContext(userId, message)
    : { user: null, weightedResults: [], totalRelevance: 0, sourcesUsed: [] };
  
  // Step 6: Call user's assigned API using new provider abstraction (fallback or non-agent tasks)
    const response = await callUserApiWithProvider(
      apiAssignment,
      taskAnalysis,
      message,
      userContext,
      conversationHistory,
      userId
    );
  
  return {
    response,
    apiUsed: apiAssignment.providerName
  };
}

// Task Analysis now handled by TaskAnalysisEngine service (see imports)

/**
 * User Context Retriever - Enhanced with Semantic Search
 * Retrieves relevant user profile content for AI context using embeddings
 */
async function retrieveUserContext(userId: string, query: string): Promise<any> {
  try {
    // Get basic user info
    const userResult = await pool.query(
      'SELECT id, first_name, last_name, current_institution, research_interests FROM users WHERE id = $1',
      [userId]
    );
    
    const user = userResult.rows[0] || null;
    
    // Generate embedding for query
    let queryEmbedding: number[] | null = null;
    try {
      queryEmbedding = await generateEmbedding(query, userId);
    } catch (error) {
      console.log('Could not generate query embedding, using keyword search');
    }
    
    // Retrieve relevant content using semantic search
    const relevantContent: any[] = [];
    
    if (queryEmbedding) {
      // Search in ai_training_data using cosine similarity (calculated in JS)
      const trainingDataResult = await pool.query(
        `SELECT 
          source_type,
          source_id,
          title,
          content,
          embedding
        FROM ai_training_data
        WHERE user_id = $1 
          AND processed = true
          AND embedding IS NOT NULL
        LIMIT 50`,
        [userId]
      );
      
      // Calculate cosine similarity for each result
      const similarities = trainingDataResult.rows.map(row => {
        try {
          const storedEmbedding = typeof row.embedding === 'string' 
            ? JSON.parse(row.embedding) 
            : row.embedding;
          
          const similarity = cosineSimilarity(queryEmbedding, storedEmbedding);
          
          return {
            type: row.source_type,
            id: row.source_id,
            title: row.title,
            content: row.content?.substring(0, 500), // Truncate for context
            similarity
          };
        } catch (error) {
          return null;
        }
      }).filter((item): item is any => item !== null && item.similarity > 0.3);
      
      // Sort by similarity and take top 5
      relevantContent.push(...similarities
        .sort((a, b) => b.similarity - a.similarity)
        .slice(0, 5));
    }
    
    // Get user's recent papers
    const papersResult = await pool.query(
      `SELECT id, title, abstract, journal, year 
       FROM papers 
       WHERE user_id = $1 
       ORDER BY created_at DESC 
       LIMIT 10`,
      [userId]
    );
    
    // Get user's recent Personal NoteBook entries
    const notebooksResult = await pool.query(
      `SELECT id, title, content, methodology, results, conclusions
       FROM lab_notebook_entries 
       WHERE user_id = $1 
       ORDER BY created_at DESC 
       LIMIT 10`,
      [userId]
    );
    
    // Get user's protocols
    const protocolsResult = await pool.query(
      `SELECT id, title, description, content
       FROM protocols 
       WHERE user_id = $1 
       ORDER BY created_at DESC 
       LIMIT 10`,
      [userId]
    );
    
    return {
      user,
      papers: papersResult.rows,
      notebooks: notebooksResult.rows,
      protocols: protocolsResult.rows,
      data: [],
      relevantContent: relevantContent.filter(c => c.similarity > 0.3) // Only highly relevant
    };
  } catch (error) {
    console.error('Error retrieving user context:', error);
    return { 
      user: null, 
      papers: [], 
      notebooks: [], 
      protocols: [], 
      data: [],
      relevantContent: []
    };
  }
}

/**
 * Calculate cosine similarity between two vectors
 */
function cosineSimilarity(vecA: number[], vecB: number[]): number {
  if (!vecA || !vecB || vecA.length !== vecB.length) return 0;
  
  let dotProduct = 0;
  let normA = 0;
  let normB = 0;
  
  for (let i = 0; i < vecA.length; i++) {
    dotProduct += vecA[i] * vecB[i];
    normA += vecA[i] * vecA[i];
    normB += vecB[i] * vecB[i];
  }
  
  const denominator = Math.sqrt(normA) * Math.sqrt(normB);
  return denominator === 0 ? 0 : dotProduct / denominator;
}

/**
 * Generate embedding for text (reusing existing functionality)
 */
async function generateEmbedding(text: string, userId?: string): Promise<number[]> {
  try {
    let apiKey = process.env.OPENAI_API_KEY;
    let endpoint = 'https://api.openai.com/v1/embeddings';
    let model = 'text-embedding-3-small';
    let defaultProvider = 'openai';
    
    if (userId) {
      try {
        defaultProvider = await getUserDefaultProvider(userId, 'embedding') || 'openai';
        const userApiKey = await getUserApiKey(userId, defaultProvider);
        
        if (userApiKey) {
          apiKey = userApiKey;
          
          if (defaultProvider === 'google_gemini') {
            endpoint = `https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent?key=${apiKey}`;
            model = 'embedding-001';
          }
        }
      } catch (error) {
        console.log('Using default embedding provider');
      }
    }
    
    // For OpenAI
    if (defaultProvider === 'openai' || !defaultProvider) {
      const response = await axios.post(
        endpoint,
        {
          input: text,
          model: model
        },
        {
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
          }
        }
      );
      
      return response.data.data[0].embedding;
    }
    
    // For Google Gemini
    if (defaultProvider === 'google_gemini') {
      const response = await axios.post(
        endpoint,
        {
          model: model,
          content: { parts: [{ text: text }] }
        },
        {
          headers: {
            'Content-Type': 'application/json'
          }
        }
      );
      
      return response.data.embedding.values;
    }
    
    throw new Error('Unsupported provider');
  } catch (error) {
    console.error('Error generating embedding:', error);
    throw error;
  }
}

/**
 * Call User's Assigned API using Provider Abstraction
 * Uses the new AIProvider interface for standardized API calls
 */
async function callUserApiWithProvider(
  apiAssignment: { provider: string; providerName: string; apiKey: string },
  taskAnalysis: TaskAnalysis,
  message: string,
  userContext: any,
  conversationHistory: any[],
  userId?: string
): Promise<string> {
  try {
    const { provider, apiKey } = apiAssignment;
    
    // Create provider instance using factory
    const aiProvider = AIProviderFactory.createProvider(provider, apiKey);
    
    // Build context string
    const contextString = buildContextString(userContext, taskAnalysis.parameters);
    
    // Build prompt based on task type
    const systemPrompt = buildSystemPrompt(taskAnalysis, userContext);
    const userPrompt = contextString 
      ? `${message}\n\n--- Context ---\n${contextString}`
      : message;
    
    // Prepare messages
    const messages: ChatMessage[] = [
      { role: 'system', content: systemPrompt },
      ...conversationHistory.slice(-10).map((msg: any) => ({
        role: (msg.role === 'assistant' ? 'assistant' : 'user') as 'user' | 'assistant',
        content: msg.content
      })),
      { role: 'user', content: userPrompt }
    ];
    
    // Call provider using abstraction
    const response = await aiProvider.chat(messages, {
      apiKey: apiKey,
      temperature: 0.7,
      maxTokens: 2000
    });
    
    return response.content;
  } catch (error: any) {
    console.error('Error calling user API:', error);
    return `Error: ${error.message || 'Failed to process request with your assigned API. Please check your API key and try again.'}`;
  }
}

/**
 * Build system prompt based on task type
 */
function buildSystemPrompt(taskAnalysis: TaskAnalysis, userContext: any): string {
  const taskDescriptions: Record<string, string> = {
    'paper_finding': 'You are a research assistant specialized in finding and analyzing academic papers. Provide comprehensive search results with summaries.',
    'abstract_writing': 'You are a scientific writing assistant. Generate well-structured abstracts following academic standards.',
    'content_writing': 'You are a professional content writer. Create high-quality, well-structured content.',
    'idea_generation': 'You are a research ideation expert. Generate creative and feasible research ideas.',
    'proposal_writing': 'You are a grant writing specialist. Create comprehensive research proposals.',
    'data_analysis': 'You are a data analysis expert. Analyze experimental data and provide insights.',
    'image_creation': 'You are an image generation assistant. Create visual content based on descriptions.',
    'paper_generation': 'You are a scientific paper writing assistant. Generate complete research papers.',
    'presentation_generation': 'You are a presentation creator. Generate professional presentation content.',
    'code_generation': 'You are a code generation assistant. Write clean, well-documented code.',
    'translation': 'You are a translation expert. Provide accurate translations.',
    'summarization': 'You are a summarization expert. Create concise, informative summaries.'
  };
  
  const basePrompt = taskDescriptions[taskAnalysis.taskType] || 'You are a helpful research assistant.';
  const userName = userContext.user?.first_name ? ` The user's name is ${userContext.user.first_name}.` : '';
  
  return `${basePrompt}${userName} Provide accurate, helpful responses based on the user's research context.`;
}

/**
 * Call OpenAI API
 */
async function callOpenAI(apiKey: string, systemPrompt: string, userPrompt: string, conversationHistory: any[]): Promise<string> {
  const messages = [
    { role: 'system', content: systemPrompt },
    ...conversationHistory.slice(-10), // Last 10 messages for context
    { role: 'user', content: userPrompt }
  ];
  
  const response = await axios.post(
    'https://api.openai.com/v1/chat/completions',
    {
      model: 'gpt-4',
      messages,
      temperature: 0.7,
      max_tokens: 2000
    },
    {
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      }
    }
  );
  
  return response.data.choices[0].message.content;
}

/**
 * Call Google Gemini API
 */
async function callGoogleGemini(apiKey: string, systemPrompt: string, userPrompt: string, conversationHistory: any[]): Promise<string> {
  const response = await axios.post(
    `https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${apiKey}`,
    {
      contents: [{
        parts: [{ text: `${systemPrompt}\n\n${userPrompt}` }]
      }]
    },
    {
      headers: {
        'Content-Type': 'application/json'
      }
    }
  );
  
  return response.data.candidates[0].content.parts[0].text;
}

/**
 * Call Anthropic Claude API
 */
async function callAnthropicClaude(apiKey: string, systemPrompt: string, userPrompt: string, conversationHistory: any[]): Promise<string> {
  const response = await axios.post(
    'https://api.anthropic.com/v1/messages',
    {
      model: 'claude-3-opus-20240229',
      max_tokens: 2000,
      system: systemPrompt,
      messages: [
        ...conversationHistory.slice(-10),
        { role: 'user', content: userPrompt }
      ]
    },
    {
      headers: {
        'x-api-key': apiKey,
        'anthropic-version': '2023-06-01',
        'Content-Type': 'application/json'
      }
    }
  );
  
  return response.data.content[0].text;
}

/**
 * Call Perplexity API
 */
async function callPerplexity(apiKey: string, systemPrompt: string, userPrompt: string, conversationHistory: any[]): Promise<string> {
  const messages = [
    { role: 'system', content: systemPrompt },
    ...conversationHistory.slice(-10),
    { role: 'user', content: userPrompt }
  ];
  
  const response = await axios.post(
    'https://api.perplexity.ai/chat/completions',
    {
      model: 'llama-3.1-sonar-large-128k-online',
      messages
    },
    {
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      }
    }
  );
  
  return response.data.choices[0].message.content;
}

// Removed routeToAgent - now handled by callUserApi

/**
 * Convert EnhancedRAGSystem context to agent-compatible format
 */
function convertEnhancedContextToAgentFormat(enhancedContext: any): any {
  // If already in legacy format, return as-is
  if (enhancedContext.papers || enhancedContext.notebooks) {
    return enhancedContext;
  }
  
  // Convert EnhancedRAGSystem format to legacy format for agent compatibility
  const converted: any = {
    user: enhancedContext.user,
    papers: [],
    notebooks: [],
    protocols: [],
    experiments: [],
    relevantContent: []
  };
  
  // Convert weighted results to legacy format
  enhancedContext.weightedResults?.forEach((result: any) => {
    const item = {
      type: result.source,
      id: result.metadata?.id,
      title: result.metadata?.title || 'Untitled',
      content: result.content,
      similarity: result.relevanceScore
    };
    
    switch (result.source) {
      case 'paper':
        converted.papers.push({ id: item.id, title: item.title, abstract: item.content });
        break;
      case 'lab_notebook_entry':
        converted.notebooks.push({ id: item.id, title: item.title, content: item.content });
        break;
      case 'protocol':
        converted.protocols.push({ id: item.id, title: item.title, description: item.content });
        break;
      case 'experiment':
        converted.experiments.push({ id: item.id, title: item.title, description: item.content });
        break;
      default:
        converted.relevantContent.push(item);
    }
  });
  
  return converted;
}

/**
 * Build context string from user context and parameters
 */
function buildContextString(userContext: any, parameters: any): string {
  const parts: string[] = [];
  
  if (userContext.user) {
    parts.push(`User: ${userContext.user.first_name} ${userContext.user.last_name}`);
    if (userContext.user.current_institution) {
      parts.push(`Institution: ${userContext.user.current_institution}`);
    }
    if (userContext.user.research_interests) {
      parts.push(`Research Interests: ${userContext.user.research_interests}`);
    }
  }

  // Add enhanced personalization data
  if (userContext.researchInterests && userContext.researchInterests.length > 0) {
    parts.push(`Research Interests: ${userContext.researchInterests.join(', ')}`);
  }

  if (userContext.activeProjects && userContext.activeProjects.length > 0) {
    parts.push(`\nActive Projects:`);
    userContext.activeProjects.slice(0, 3).forEach((project: any) => {
      parts.push(`- ${project.title}: ${project.description || 'No description'}`);
    });
  }

  if (userContext.recentProtocols && userContext.recentProtocols.length > 0) {
    parts.push(`\nRecent Protocols:`);
    userContext.recentProtocols.slice(0, 3).forEach((protocol: any) => {
      parts.push(`- ${protocol.title} (${protocol.category || 'General'})`);
    });
  }

  if (userContext.interactionPatterns) {
    const patterns = userContext.interactionPatterns;
    if (patterns.commonTopics.length > 0) {
      parts.push(`\nCommon Research Topics: ${patterns.commonTopics.slice(0, 5).join(', ')}`);
    }
  }
  
  if (parameters.topic) {
    parts.push(`Topic: ${parameters.topic}`);
  }
  
  // Handle both EnhancedRAGSystem and legacy formats
  if (userContext.weightedResults && userContext.weightedResults.length > 0) {
    parts.push(`\nRelevant Research Context:`);
    userContext.weightedResults.slice(0, 3).forEach((item: any, idx: number) => {
      parts.push(`${idx + 1}. [${item.source}] ${item.metadata?.title || 'Untitled'}: ${item.content?.substring(0, 200)}...`);
    });
  } else if (userContext.relevantContent && userContext.relevantContent.length > 0) {
    parts.push(`\nRelevant Research Context:`);
    userContext.relevantContent.slice(0, 3).forEach((item: any, idx: number) => {
      parts.push(`${idx + 1}. ${item.title}: ${item.content?.substring(0, 200)}...`);
    });
  }
  
  return parts.join('\n');
}

// ==============================================
// INDIVIDUAL TASK HANDLERS - Enhanced with Context
// ==============================================

async function handlePaperFinding(
  message: string, 
  context: any, 
  parameters: any,
  contextString: string
): Promise<string> {
  const topic = parameters.topic || message.replace(/find|papers?|on|about/gi, '').trim();
  
  // TODO: Phase 2.4 - Implement full PaperFindingAgent with multi-database search
  // For now, return intelligent response with context awareness
  
  let response = `I'll help you find papers on "${topic}".\n\n`;
  
  if (context.relevantContent && context.relevantContent.length > 0) {
    response += `Based on your research history, I found ${context.relevantContent.length} relevant items. `;
  }
  
  response += `I'm searching multiple databases (PubMed, arXiv, CrossRef) and will return curated results with summaries.\n\n`;
  response += `**This feature is being enhanced** - Soon I'll:\n`;
  response += `‚Ä¢ Search across multiple databases\n`;
  response += `‚Ä¢ Rank by relevance to your research\n`;
  response += `‚Ä¢ Provide AI-generated summaries\n`;
  response += `‚Ä¢ Filter by date, citations, and impact`;
  
  return response;
}

async function handleAbstractWriting(
  message: string, 
  context: any, 
  parameters: any,
  contextString: string
): Promise<string> {
  // TODO: Phase 2.5 - Implement AbstractWritingAgent
  let response = `I'll help you write an abstract.\n\n`;
  
  if (context.notebooks && context.notebooks.length > 0) {
    response += `I found ${context.notebooks.length} Personal NoteBook entries that I can use as context. `;
  }
  
  if (context.relevantContent && context.relevantContent.length > 0) {
    response += `I also have ${context.relevantContent.length} relevant research items.\n\n`;
  }
  
  response += `**This feature is being enhanced** - Soon I'll:\n`;
  response += `‚Ä¢ Analyze your experimental data\n`;
  response += `‚Ä¢ Extract key findings\n`;
  response += `‚Ä¢ Generate structured abstract (Objective, Methods, Results, Conclusions)\n`;
  response += `‚Ä¢ Ensure proper formatting and length`;
  
  return response;
}

async function handleIdeaGeneration(
  message: string, 
  context: any, 
  parameters: any,
  contextString: string
): Promise<string> {
  const field = parameters.topic || context.user?.research_interests || 'your field';
  
  let response = `I'll generate research ideas for ${field}.\n\n`;
  
  if (context.papers && context.papers.length > 0) {
    response += `I've reviewed your ${context.papers.length} papers and `;
  }
  
  if (context.notebooks && context.notebooks.length > 0) {
    response += `${context.notebooks.length} Personal NoteBook entries to identify research gaps.\n\n`;
  }
  
  response += `**This feature is being enhanced** - Soon I'll:\n`;
  response += `‚Ä¢ Analyze your research history\n`;
  response += `‚Ä¢ Identify knowledge gaps\n`;
  response += `‚Ä¢ Generate novel hypotheses\n`;
  response += `‚Ä¢ Prioritize by feasibility and impact`;
  
  return response;
}

async function handleProposalWriting(
  message: string, 
  context: any, 
  parameters: any,
  contextString: string
): Promise<string> {
  let response = `I'll help you write a research proposal.\n\n`;
  
  if (contextString) {
    response += `I have your research context ready to incorporate.\n\n`;
  }
  
  response += `**This feature is being enhanced** - Soon I'll:\n`;
  response += `‚Ä¢ Generate comprehensive proposal structure\n`;
  response += `‚Ä¢ Write sections based on your research\n`;
  response += `‚Ä¢ Include budget planning\n`;
  response += `‚Ä¢ Format according to grant requirements`;
  
  return response;
}

async function handleDataAnalysis(
  message: string, 
  context: any, 
  parameters: any,
  contextString: string
): Promise<string> {
  let response = `I'll analyze your experimental data.\n\n`;
  
  if (context.notebooks && context.notebooks.length > 0) {
    response += `I found ${context.notebooks.length} Personal NoteBook entries with experimental data.\n\n`;
  }
  
  response += `**This feature is being enhanced** - Soon I'll:\n`;
  response += `‚Ä¢ Load and parse your experimental data\n`;
  response += `‚Ä¢ Perform statistical analysis\n`;
  response += `‚Ä¢ Generate visualizations\n`;
  response += `‚Ä¢ Provide insights and interpretations`;
  
  return response;
}

// ==============================================
// COMPLEX WORKFLOW HANDLERS - Enhanced
// ==============================================

async function handlePaperGenerationWorkflow(
  message: string, 
  context: any,
  parameters: any,
  contextString: string
): Promise<string> {
  // TODO: Phase 3 - Implement PaperGenerationPipeline
  let response = `I'll generate a complete research paper from your data.\n\n`;
  
  if (context.notebooks && context.notebooks.length > 0) {
    response += `I found ${context.notebooks.length} Personal NoteBook entries to work with.\n\n`;
  }
  
  response += `**This complex workflow will:**\n`;
  response += `1. üìä Read and analyze your experimental data\n`;
  response += `2. üìù Write Introduction section\n`;
  response += `3. üî¨ Write Methods section\n`;
  response += `4. üìà Write Results section with figures\n`;
  response += `5. üí≠ Write Discussion section\n`;
  response += `6. üìö Add references and citations\n`;
  response += `7. ‚ú® Format for publication\n\n`;
  response += `**Status:** This feature is being developed. You'll be able to generate complete papers automatically!`;
  
  return response;
}

async function handlePresentationGenerationWorkflow(
  message: string, 
  context: any,
  parameters: any,
  contextString: string
): Promise<string> {
  // TODO: Phase 3 - Implement PresentationGenerationPipeline
  let response = `I'll create a presentation from your research.\n\n`;
  
  if (context.papers && context.papers.length > 0) {
    response += `I'll use your ${context.papers.length} papers and research data.\n\n`;
  }
  
  response += `**This complex workflow will:**\n`;
  response += `1. üîç Extract key findings from your research\n`;
  response += `2. üìÑ Generate slide content\n`;
  response += `3. üìä Create visualizations and figures\n`;
  response += `4. üé® Format slides professionally\n`;
  response += `5. üìù Add speaker notes\n\n`;
  response += `**Status:** This feature is being developed. You'll be able to generate complete presentations automatically!`;
  
  return response;
}

async function handleGeneralResearch(
  message: string, 
  context: any,
  parameters: any,
  contextString: string
): Promise<string> {
  const userName = context.user?.first_name || 'there';
  let response = `Hello ${userName}! üëã\n\n`;
  
  if (context.relevantContent && context.relevantContent.length > 0) {
    response += `I've reviewed your research and found ${context.relevantContent.length} relevant items.\n\n`;
  }
  
  response += `I'm your AI Research Agent. I can help you with:\n\n`;
  response += `‚Ä¢ üîç Finding and analyzing papers\n`;
  response += `‚Ä¢ ‚úçÔ∏è Writing abstracts, proposals, and papers\n`;
  response += `‚Ä¢ üí° Generating research ideas\n`;
  response += `‚Ä¢ üìä Analyzing experimental data\n`;
  response += `‚Ä¢ üìΩÔ∏è Creating presentations\n\n`;
  response += `Just ask me anything about your research!`;
  
  return response;
}

export default router;

